{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NmAwkt2J53-K"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "from copy import deepcopy\n",
        "from collections import OrderedDict\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm_notebook\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import SGD,Adam,lr_scheduler\n",
        "from torch.utils.data import random_split\n",
        "import torchvision\n",
        "from torchvision import transforms,models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiscQCQL6_ou",
        "outputId": "9a4238c8-3a29-40f0-e9f3-d856ff825881"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 70541236.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256), #Resizing all the images\n",
        "    transforms.CenterCrop(224),#Cropping all from centre\n",
        "    transforms.ToTensor(),#Converting to tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),#Normalize all using the mean and standard deviation (x-mu/rho)\n",
        "]) #Data preparation\n",
        "traindata = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainset,valset = random_split(traindata,[42000,8000])\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,shuffle=True)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=64,shuffle=False)\n",
        "\n",
        "test_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=4, shuffle=False, num_workers=2)  #same for the testing data\n",
        "\n",
        "classes = ('Airplane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTAWxoRz7MT1",
        "outputId": "988aecbc-84a8-4ba3-e9f0-eea1903dc47d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 147MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['base', 'drop', 'final']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        base = models.resnet18(pretrained=True)\n",
        "        self.base = nn.Sequential(*list(base.children())[:-1])\n",
        "        in_features = base.fc.in_features\n",
        "        self.drop = nn.Dropout()\n",
        "        self.final = nn.Linear(in_features,10)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.base(x)\n",
        "        x = self.drop(x.view(-1,self.final.in_features))\n",
        "        return self.final(x)\n",
        "\n",
        "model = Model().cuda()\n",
        "[x for x,y in model.named_children()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FMJXu_t4AI1v"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "param_groups = [\n",
        "    {'params':model.base.parameters(),'lr':.0001},\n",
        "    {'params':model.final.parameters(),'lr':.001}\n",
        "]\n",
        "optimizer = Adam(param_groups)\n",
        "lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
        "states = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGBZWVLnBcJI",
        "outputId": "15c2eb03-73f4-46ae-d9d9-cd65a61847b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1: 0.43862458271072025,Train Acc:85.26428571428572%\n",
            "Val accuracy:92.1625%\n",
            "Train loss 2: 0.12434501542080016,Train Acc:96.13095238095238%\n",
            "Val accuracy:94.25%\n",
            "Train loss 3: 0.08531353051747595,Train Acc:97.41904761904762%\n",
            "Val accuracy:94.05%\n",
            "Train loss 4: 0.08253810505781854,Train Acc:97.58809523809524%\n",
            "Val accuracy:94.1875%\n",
            "Train loss 5: 0.08204647142688433,Train Acc:97.60714285714286%\n",
            "Val accuracy:94.0125%\n",
            "Finished Training\n",
            "CPU times: user 17min 1s, sys: 1min 36s, total: 18min 38s\n",
            "Wall time: 18min 29s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "best_val_acc = -1000\n",
        "best_val_model = None\n",
        "for epoch in range(5):\n",
        "    model.train(True)\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.cuda(),labels.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        out = torch.argmax(outputs.detach(),dim=1)\n",
        "        assert out.shape==labels.shape\n",
        "        running_acc += (labels==out).sum().item()\n",
        "    print(f\"Train loss {epoch+1}: {running_loss/len(trainset)},Train Acc:{running_acc*100/len(trainset)}%\")\n",
        "\n",
        "    correct = 0\n",
        "    model.train(False)\n",
        "    with torch.no_grad():\n",
        "        for inputs,labels in valloader:\n",
        "\n",
        "          out = model(inputs.cuda()).cpu()\n",
        "          out = torch.argmax(out,dim=1)\n",
        "          acc = (out==labels).sum().item()\n",
        "          correct += acc\n",
        "    print(f\"Val accuracy:{correct*100/len(valset)}%\")\n",
        "    if correct>best_val_acc:\n",
        "\n",
        "      best_val_acc = correct\n",
        "      best_val_model = deepcopy(model.state_dict())\n",
        "    lr_scheduler.step()\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tCYyfTlvCKvt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae84c8a2-1e2e-4ab4-b1d0-bdc3401e941d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 94.06%\n",
            "CPU times: user 15.9 s, sys: 2.67 s, total: 18.6 s\n",
            "Wall time: 28 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "correct = 0\n",
        "model.load_state_dict(best_val_model)\n",
        "model.train(False)\n",
        "with torch.no_grad():\n",
        "    for inputs,labels in testloader:\n",
        "        out = model(inputs.cuda()).cpu()\n",
        "        out = torch.argmax(out,dim=1)\n",
        "        acc = (out==labels).sum().item()\n",
        "\n",
        "        correct += acc\n",
        "print(f\"Test accuracy: {correct*100/len(test_data)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGujmKJnCiDY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}